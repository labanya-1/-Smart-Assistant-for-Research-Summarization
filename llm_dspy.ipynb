{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3usZGZB3P2S6iueFIWA7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/labanya-1/-Smart-Assistant-for-Research-Summarization/blob/main/llm_dspy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2CnORkrcrn7",
        "outputId": "4f0df144-324b-45da-af8b-fba35fea432a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m75 packages\u001b[0m \u001b[2min 1.10s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m13 packages\u001b[0m \u001b[2min 567ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 9ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m13 packages\u001b[0m \u001b[2min 149ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1masyncer\u001b[0m\u001b[2m==0.0.8\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbackoff\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.10.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdiskcache\u001b[0m\u001b[2m==5.6.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy\u001b[0m\u001b[2m==3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mdspy-ai\u001b[0m\u001b[2m==3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mfastuuid\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgepa\u001b[0m\u001b[2m==0.0.17\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.76.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.67.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjson-repair\u001b[0m\u001b[2m==0.54.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlitellm\u001b[0m\u001b[2m==1.80.10\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmagicattr\u001b[0m\u001b[2m==0.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.6.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!uv pip install dspy-ai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import dspy\n",
        "import copy\n",
        "from typing import List, Optional\n",
        "from typing import Literal, Dict, Union\n",
        "from dspy.adapters import XMLAdapter"
      ],
      "metadata": {
        "id": "LM0FAMgzdAW_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY=\"ak_23N09U4xZ4U04m46AW13S8rS1533S\"\n",
        "main_lm = dspy.LM(\"openai/LongCat-Flash-Chat\", api_key=API_KEY,api_base=\"https://api.longcat.chat/openai/v1\")\n",
        "\n",
        "dspy.settings.configure(lm=main_lm,adapter=dspy.XMLAdapter())"
      ],
      "metadata": {
        "id": "qeQJRCGAdF0S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHErehn1dO40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 1.  ENTITY + ATTRIBUTE EXTRACTION\n",
        "# ---------------------------------------------------------\n",
        "# import dspy\n",
        "from typing import List, Dict, Tuple\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class EntityWithAttr(BaseModel):\n",
        "    entity: str = Field(description=\"the named entity\")\n",
        "    attr_type: str = Field(description=\"semantic type of the entity (e.g. Drug, Disease, Symptom, etc.)\")\n",
        "\n",
        "class ExtractEntities(dspy.Signature):\n",
        "    \"\"\"From the paragraph extract all relevant entities and their semantic attribute types.\"\"\"\n",
        "    paragraph: str = dspy.InputField(desc=\"input paragraph\")\n",
        "    entities: List[EntityWithAttr] = dspy.OutputField(desc=\"list of entities and their attribute types\")\n",
        "\n",
        "extractor = dspy.Predict(ExtractEntities)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2.  DEDUPLICATOR (recursive batching + confidence loop)\n",
        "# ---------------------------------------------------------\n",
        "class DeduplicateEntities(dspy.Signature):\n",
        "    \"\"\"Given a list of (entity, attr_type) decide which ones are duplicates.\n",
        "    Return a deduplicated list and a confidence that the remaining items are ALL distinct.\"\"\"\n",
        "    items: List[EntityWithAttr] = dspy.InputField(desc=\"batch of entities to deduplicate\")\n",
        "    deduplicated: List[EntityWithAttr] = dspy.OutputField(desc=\"deduplicated list\")\n",
        "    confidence: float = dspy.OutputField(\n",
        "        desc=\"confidence (0-1) that every item in deduplicated is semantically distinct\"\n",
        "    )\n",
        "\n",
        "dedup_predictor = dspy.ChainOfThought(DeduplicateEntities)\n",
        "\n",
        "def deduplicate_with_lm(\n",
        "    items: List[EntityWithAttr],\n",
        "    *,\n",
        "    batch_size: int = 10,\n",
        "    target_confidence: float = 0.9,\n",
        ") -> List[EntityWithAttr]:\n",
        "    \"\"\"\n",
        "    Recursively deduplicate using the LM.\n",
        "    Works by:\n",
        "      1. splitting into batches of `batch_size`\n",
        "      2. for each batch asking the LM for duplicates + confidence\n",
        "      3. rerunning the batch until confidence >= target_confidence\n",
        "      4. concatenating results from all batches\n",
        "    \"\"\"\n",
        "    if not items:\n",
        "        return []\n",
        "\n",
        "    # helper to process one batch\n",
        "    def _process_batch(batch: List[EntityWithAttr]) -> List[EntityWithAttr]:\n",
        "        while True:\n",
        "            pred = dedup_predictor(items=batch)\n",
        "            if pred.confidence >= target_confidence:\n",
        "                return pred.deduplicated\n",
        "            # otherwise loop again with same batch\n",
        "\n",
        "    # split into batches and process\n",
        "    results = []\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        batch = items[i : i + batch_size]\n",
        "        results.extend(_process_batch(batch))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "--mBs-_oh_-t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4Qn8yZddTbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4.  RELATION EXTRACTION\n",
        "# ---------------------------------------------------------\n",
        "class Relation(BaseModel):\n",
        "    subj: str = Field(description=\"subject entity (exact string as in deduplicated list)\")\n",
        "    pred: str = Field(description=\"short predicate / relation phrase\")\n",
        "    obj:  str = Field(description=\"object entity (exact string as in deduplicated list)\")\n",
        "\n",
        "class ExtractRelations(dspy.Signature):\n",
        "    \"\"\"Given the original paragraph and a list of unique entities, extract all factual (subject, predicate, object) triples that are explicitly stated or clearly implied.\"\"\"\n",
        "    paragraph: str = dspy.InputField(desc=\"original paragraph\")\n",
        "    entities:  List[str] = dspy.InputField(desc=\"list of deduplicated entity strings\")\n",
        "    relations: List[Relation] = dspy.OutputField(desc=\"list of subject-predicate-object triples\")\n",
        "\n",
        "rel_predictor = dspy.ChainOfThought(ExtractRelations)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5.  MERMAID SERIALISER  (revised)\n",
        "# ---------------------------------------------------------\n",
        "def triples_to_mermaid(\n",
        "    triples: list[Relation],\n",
        "    entity_list: list[str],\n",
        "    max_label_len: int = 40\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Convert triples to a VALID Mermaid flowchart LR diagram.\n",
        "    \"\"\"\n",
        "    entity_set = {e.strip().lower() for e in entity_list}\n",
        "    lines = [\"flowchart LR\"]\n",
        "\n",
        "    def _make_id(s: str) -> str:\n",
        "        # Create valid Mermaid node ID (no spaces or special chars)\n",
        "        return s.strip().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"-\", \"_\")\n",
        "\n",
        "    for t in triples:\n",
        "        subj_norm, obj_norm = t.subj.strip().lower(), t.obj.strip().lower()\n",
        "\n",
        "        if obj_norm in entity_set:\n",
        "            src, dst, lbl = t.subj, t.obj, t.pred\n",
        "        elif subj_norm in entity_set:\n",
        "            src, dst, lbl = t.obj, t.subj, t.pred\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Sanitize label\n",
        "        lbl = lbl.strip()\n",
        "        if len(lbl) > max_label_len:\n",
        "            lbl = lbl[:max_label_len - 3] + \"...\"\n",
        "\n",
        "        # Use valid IDs with display labels\n",
        "        src_id, dst_id = _make_id(src), _make_id(dst)\n",
        "        lines.append(f'    {src_id}[\"{src}\"] -->|{lbl}| {dst_id}[\"{dst}\"]')\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6.  END-TO-END RUN  (FIXED)\n",
        "# ---------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    paragraph = \"\"\"\n",
        "    Effects of organic amendments on productivity, nitrogen uptake, and protein content in pea--barley intercrops compared to the sole crops\n",
        "    agricultural\n",
        "    barleyintercropping systemsorganic farmingpeasustainable agriculture\n",
        "\n",
        "    +1\n",
        "    Saad Mir,Vaibhav Chaudhary,Nicolò Maria Villa,Bhim Ghaley\n",
        "    Abstract\n",
        "    Cereal-legume intercropping and organic amendments are promising strategies to boost crop productivity, land use efficiency, and sustainability. However, their performance varies depending on pedo-climatic zones and crop types. In Denmark, pea-barley intercrop is commonly practiced for seed harvest and fodder production. Therefore, the objective of this study was to investigate the effects of organic amendments on productivity, nitrogen (N) uptake, and barley grain protein in pea-barley intercrops (PB IC) compared to sole crops. A field trial was conducted using a strip-plot design with three cropping systems—PB IC, pea sole (PS), and barley sole (BS) with six organic amendment treatments: control (T0), biochar (T1), compost (T2), insect frass (T3), vermicompost (T4), and pelletized frass (T5). Averaged across organic amendments, PB IC increased aboveground dry biomass (AGDB) by 18–57% and grain yield by 12–135% compared to sole crops. Grain N-uptake under PB IC increased by 66–94%, compared to sole crops. PB IC suppressed weed biomass by 83% relative to PS. Averaged across cropping systems, T5 increased grain yield by 105%, N-uptake in straw by 49%, and in grains by 101%, compared to T0. Land equivalent ratio (LER) ranged from 1.15-2.47 across treatments, indicating improved land use efficiency. Barley protein content was consistently higher in PB IC than in BS. PB IC combined with organic amendments—particularly pelletized frass, significantly increased crop yield, land use efficiency, N-uptake, and grain quality. This field study provides robust evidence of the multiple benefits of integrating pea-barley intercropping with organic amendments for sustainable intensification.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 3a. extract entities (from Section 1)\n",
        "    extracted = extractor(paragraph=paragraph)\n",
        "    print(\"Extracted entities:\")\n",
        "    for e in extracted.entities:\n",
        "        print(\" -\", e.entity, \"=>\", e.attr_type)\n",
        "\n",
        "    # --- 3b. deduplicate (from Section 1)\n",
        "    unique = deduplicate_with_lm(extracted.entities, batch_size=10, target_confidence=0.9)\n",
        "    print(\"\\nDeduplicated entities:\")\n",
        "    for e in unique:\n",
        "        print(\" -\", e.entity, \"=>\", e.attr_type)\n",
        "\n",
        "    # Prepare entity strings for relation extraction\n",
        "    entity_strings = [e.entity for e in unique]\n",
        "\n",
        "    # --- 4. relation extraction\n",
        "    rel_out = rel_predictor(paragraph=paragraph, entities=entity_strings)\n",
        "    print(\"\\nExtracted relations:\")\n",
        "    for r in rel_out.relations:\n",
        "        print(\" -\", r.subj, \"--\", r.pred, \"-->\", r.obj)\n",
        "\n",
        "    # --- 5. generate Mermaid diagram\n",
        "    mermaid_code = triples_to_mermaid(\n",
        "        rel_out.relations,\n",
        "        entity_strings\n",
        "    )\n",
        "    print(\"\\nValid Mermaid diagram:\\n\")\n",
        "    print(\"mermaid\")\n",
        "    print(mermaid_code)\n",
        "    print(\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0IalWVdiHGn",
        "outputId": "4eb104ad-55c3-4873-9d05-f29f6ab2b908"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted entities:\n",
            " - organic amendments => AgriculturalPractice\n",
            " - productivity => AgriculturalMetric\n",
            " - nitrogen uptake => NutrientUptake\n",
            " - protein content => NutritionalComponent\n",
            " - pea-barley intercrops => CropSystem\n",
            " - sole crops => CropSystem\n",
            " - cereal-legume intercropping => AgriculturalPractice\n",
            " - organic farming => AgriculturalPractice\n",
            " - sustainable agriculture => AgriculturalPractice\n",
            " - Denmark => Location\n",
            " - seed harvest => AgriculturalActivity\n",
            " - fodder production => AgriculturalActivity\n",
            " - field trial => ResearchMethod\n",
            " - strip-plot design => ExperimentalDesign\n",
            " - cropping systems => AgriculturalSystem\n",
            " - pea sole => CropSystem\n",
            " - barley sole => CropSystem\n",
            " - control => Treatment\n",
            " - biochar => OrganicAmendment\n",
            " - compost => OrganicAmendment\n",
            " - insect frass => OrganicAmendment\n",
            " - vermicompost => OrganicAmendment\n",
            " - pelletized frass => OrganicAmendment\n",
            " - aboveground dry biomass => BiomassMeasure\n",
            " - grain yield => YieldMeasure\n",
            " - grain N-uptake => NutrientUptake\n",
            " - weed biomass => WeedMeasure\n",
            " - N-uptake in straw => NutrientUptake\n",
            " - land equivalent ratio => EfficiencyMetric\n",
            " - barley protein content => NutritionalComponent\n",
            " - crop yield => YieldMeasure\n",
            " - land use efficiency => EfficiencyMetric\n",
            " - grain quality => QualityMeasure\n",
            " - sustainable intensification => AgriculturalGoal\n",
            "\n",
            "Deduplicated entities:\n",
            " - organic amendments => AgriculturalPractice\n",
            " - productivity => AgriculturalMetric\n",
            " - nitrogen uptake => NutrientUptake\n",
            " - protein content => NutritionalComponent\n",
            " - pea-barley intercrops => CropSystem\n",
            " - sole crops => CropSystem\n",
            " - cereal-legume intercropping => AgriculturalPractice\n",
            " - organic farming => AgriculturalPractice\n",
            " - sustainable agriculture => AgriculturalPractice\n",
            " - Denmark => Location\n",
            " - seed harvest => AgriculturalActivity\n",
            " - fodder production => AgriculturalActivity\n",
            " - field trial => ResearchMethod\n",
            " - strip-plot design => ExperimentalDesign\n",
            " - cropping systems => AgriculturalSystem\n",
            " - pea sole => CropSystem\n",
            " - barley sole => CropSystem\n",
            " - control => Treatment\n",
            " - biochar => OrganicAmendment\n",
            " - compost => OrganicAmendment\n",
            " - insect frass => OrganicAmendment\n",
            " - vermicompost => OrganicAmendment\n",
            " - aboveground dry biomass => BiomassMeasure\n",
            " - grain yield => YieldMeasure\n",
            " - grain N-uptake => NutrientUptake\n",
            " - weed biomass => WeedMeasure\n",
            " - N-uptake in straw => NutrientUptake\n",
            " - land equivalent ratio => EfficiencyMetric\n",
            " - barley protein content => NutritionalComponent\n",
            " - crop yield => YieldMeasure\n",
            " - land use efficiency => EfficiencyMetric\n",
            " - grain quality => QualityMeasure\n",
            " - sustainable intensification => AgriculturalGoal\n",
            "\n",
            "Extracted relations:\n",
            " - pea-barley intercrops -- increased --> aboveground dry biomass\n",
            " - pea-barley intercrops -- increased --> grain yield\n",
            " - pea-barley intercrops -- increased --> grain N-uptake\n",
            " - pea-barley intercrops -- suppressed --> weed biomass\n",
            " - pea-barley intercrops -- had higher --> barley protein content\n",
            " - pelletized frass -- increased --> grain yield\n",
            " - pelletized frass -- increased --> N-uptake in straw\n",
            " - pelletized frass -- increased --> grain N-uptake\n",
            " - organic amendments -- increased --> crop yield\n",
            " - organic amendments -- increased --> land use efficiency\n",
            " - organic amendments -- increased --> N-uptake\n",
            " - organic amendments -- improved --> grain quality\n",
            " - pea-barley intercrops -- combined with --> organic amendments\n",
            " - pea-barley intercrops -- practiced for --> seed harvest\n",
            " - pea-barley intercrops -- practiced for --> fodder production\n",
            " - field trial -- used --> strip-plot design\n",
            " - field trial -- conducted in --> Denmark\n",
            " - cereal-legume intercropping -- supports --> sustainable agriculture\n",
            " - organic farming -- supports --> sustainable agriculture\n",
            " - organic amendments -- supports --> sustainable agriculture\n",
            " - pea-barley intercrops -- improves --> land use efficiency\n",
            " - pea-barley intercrops -- enhances --> sustainable intensification\n",
            " - land equivalent ratio -- indicates --> land use efficiency\n",
            " - organic amendments -- varies by --> pedo-climatic zones\n",
            " - cropping systems -- include --> pea-barley intercrops\n",
            " - cropping systems -- include --> pea sole\n",
            " - cropping systems -- include --> barley sole\n",
            " - organic amendments -- include --> biochar\n",
            " - organic amendments -- include --> compost\n",
            " - organic amendments -- include --> insect frass\n",
            " - organic amendments -- include --> vermicompost\n",
            " - organic amendments -- include --> pelletized frass\n",
            " - organic amendments -- include --> control\n",
            "\n",
            "Valid Mermaid diagram:\n",
            "\n",
            "mermaid\n",
            "flowchart LR\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|increased| aboveground_dry_biomass[\"aboveground dry biomass\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|increased| grain_yield[\"grain yield\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|increased| grain_N_uptake[\"grain N-uptake\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|suppressed| weed_biomass[\"weed biomass\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|had higher| barley_protein_content[\"barley protein content\"]\n",
            "    pelletized_frass[\"pelletized frass\"] -->|increased| grain_yield[\"grain yield\"]\n",
            "    pelletized_frass[\"pelletized frass\"] -->|increased| N_uptake_in_straw[\"N-uptake in straw\"]\n",
            "    pelletized_frass[\"pelletized frass\"] -->|increased| grain_N_uptake[\"grain N-uptake\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|increased| crop_yield[\"crop yield\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|increased| land_use_efficiency[\"land use efficiency\"]\n",
            "    N_uptake[\"N-uptake\"] -->|increased| organic_amendments[\"organic amendments\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|improved| grain_quality[\"grain quality\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|combined with| organic_amendments[\"organic amendments\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|practiced for| seed_harvest[\"seed harvest\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|practiced for| fodder_production[\"fodder production\"]\n",
            "    field_trial[\"field trial\"] -->|used| strip_plot_design[\"strip-plot design\"]\n",
            "    field_trial[\"field trial\"] -->|conducted in| Denmark[\"Denmark\"]\n",
            "    cereal_legume_intercropping[\"cereal-legume intercropping\"] -->|supports| sustainable_agriculture[\"sustainable agriculture\"]\n",
            "    organic_farming[\"organic farming\"] -->|supports| sustainable_agriculture[\"sustainable agriculture\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|supports| sustainable_agriculture[\"sustainable agriculture\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|improves| land_use_efficiency[\"land use efficiency\"]\n",
            "    pea_barley_intercrops[\"pea-barley intercrops\"] -->|enhances| sustainable_intensification[\"sustainable intensification\"]\n",
            "    land_equivalent_ratio[\"land equivalent ratio\"] -->|indicates| land_use_efficiency[\"land use efficiency\"]\n",
            "    pedo_climatic_zones[\"pedo-climatic zones\"] -->|varies by| organic_amendments[\"organic amendments\"]\n",
            "    cropping_systems[\"cropping systems\"] -->|include| pea_barley_intercrops[\"pea-barley intercrops\"]\n",
            "    cropping_systems[\"cropping systems\"] -->|include| pea_sole[\"pea sole\"]\n",
            "    cropping_systems[\"cropping systems\"] -->|include| barley_sole[\"barley sole\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|include| biochar[\"biochar\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|include| compost[\"compost\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|include| insect_frass[\"insect frass\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|include| vermicompost[\"vermicompost\"]\n",
            "    pelletized_frass[\"pelletized frass\"] -->|include| organic_amendments[\"organic amendments\"]\n",
            "    organic_amendments[\"organic amendments\"] -->|include| control[\"control\"]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_dspy_pipeline(text: str):\n",
        "    extracted = extractor(paragraph=text)\n",
        "\n",
        "    unique_entities = deduplicate_with_lm(\n",
        "        extracted.entities,\n",
        "        batch_size=10,\n",
        "        target_confidence=0.9\n",
        "    )\n",
        "\n",
        "    entity_strings = [e.entity for e in unique_entities]\n",
        "\n",
        "    relations = rel_predictor(\n",
        "        paragraph=text,\n",
        "        entities=entity_strings\n",
        "    ).relations\n",
        "\n",
        "    return unique_entities, relations\n"
      ],
      "metadata": {
        "id": "rVVt47oldXls"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4 requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-llS8BfgvW",
        "outputId": "cf105966-8a3a-4f48-c665-452d3855f79f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url: str, max_chars: int = 12000) -> str:\n",
        "    html = requests.get(url, timeout=20).text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    for tag in soup([\"script\", \"style\", \"nav\", \"footer\", \"header\"]):\n",
        "        tag.decompose()\n",
        "\n",
        "    text = \" \".join(soup.stripped_strings)\n",
        "    return text[:max_chars]\n"
      ],
      "metadata": {
        "id": "PPAgIGkrfjEK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_url = \"https://en.wikipedia.org/wiki/Sustainable_agriculture\"\n",
        "text = extract_text_from_url(test_url)\n",
        "print(text[:1000])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7i9XOnRfmL_",
        "outputId": "0446aac0-8c44-4d59-f822-3e7c3c9b89c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please set a user-agent and respect our robot policy https://w.wiki/4wJS. See also https://phabricator.wikimedia.org/T400119.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities, relations = run_dspy_pipeline(text)\n"
      ],
      "metadata": {
        "id": "AkfWK4lvfojS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entity_strings = [e.entity for e in entities]\n",
        "\n",
        "mermaid_code = triples_to_mermaid(\n",
        "    relations,\n",
        "    entity_strings\n",
        ")\n",
        "\n",
        "print(mermaid_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk47L76TftR0",
        "outputId": "cfcf0fd3-a77b-4ae9-8872-78966faeec15"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowchart LR\n",
            "    user_agent[\"user-agent\"] -->|respect| robot_policy[\"robot policy\"]\n",
            "    https://w.wiki/4wJS[\"https://w.wiki/4wJS\"] -->|hosts| robot_policy[\"robot policy\"]\n",
            "    https://phabricator.wikimedia.org/T400119[\"https://phabricator.wikimedia.org/T400119\"] -->|see also| robot_policy[\"robot policy\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_mermaid(code: str, index: int):\n",
        "    filename = f\"mermaid_{index}.md\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(\"```mermaid\\n\")\n",
        "        f.write(code)\n",
        "        f.write(\"\\n```\")\n",
        "    return filename\n"
      ],
      "metadata": {
        "id": "4Yrbhx4Ff1rn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_mermaid(mermaid_code, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "raTN86IxgBgp",
        "outputId": "cbbb5559-c36c-42a8-97ce-a629dc9cc04b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mermaid_1.md'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def entities_to_csv_rows(entities, url):\n",
        "    rows = []\n",
        "    for e in entities:\n",
        "        rows.append({\n",
        "            \"link\": url,\n",
        "            \"tag\": e.entity,\n",
        "            \"tag_type\": e.attr_type\n",
        "        })\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "bQc-8vdBgDjU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLS = [\n",
        "    \"https://en.wikipedia.org/wiki/Sustainable_agriculture\",\n",
        "    \"https://www.nature.com/articles/d41586-025-03353-5\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S1043661820315152\",\n",
        "    \"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10457221/\",\n",
        "    \"https://www.fao.org/3/y4671e/y4671e06.htm\",\n",
        "    \"https://www.medscape.com/viewarticle/time-reconsider-tramadol-chronic-pain-2025a1000ria\",\n",
        "    \"https://www.sciencedirect.com/science/article/pii/S0378378220307088\",\n",
        "    \"https://www.frontiersin.org/news/2025/09/01/rectangle-telescope-finding-habitable-planets\",\n",
        "    \"https://www.medscape.com/viewarticle/second-dose-boosts-shingles-protection-adults-aged-65-years-2025a1000ro7\",\n",
        "    \"https://www.theguardian.com/global-development/2025/oct/13/astro-ambassadors-stargazers-himalayas-hanle-ladakh-india\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "f5sUQ1V7gFtX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_csv_rows = []\n",
        "\n",
        "for i, url in enumerate(URLS, start=1):\n",
        "    print(f\"Processing {i}/10\")\n",
        "\n",
        "    text = extract_text_from_url(url)\n",
        "\n",
        "    entities, relations = run_dspy_pipeline(text)\n",
        "\n",
        "    entity_strings = [e.entity for e in entities]\n",
        "\n",
        "    mermaid = triples_to_mermaid(relations, entity_strings)\n",
        "\n",
        "    save_mermaid(mermaid, i)\n",
        "\n",
        "    all_csv_rows.extend(entities_to_csv_rows(entities, url))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVzhG0T-gHkc",
        "outputId": "4aa1ef94-b445-477c-ee49-83b5ee5b9fa2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1/10\n",
            "Processing 2/10\n",
            "Processing 3/10\n",
            "Processing 4/10\n",
            "Processing 5/10\n",
            "Processing 6/10\n",
            "Processing 7/10\n",
            "Processing 8/10\n",
            "Processing 9/10\n",
            "Processing 10/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique = {}\n",
        "for r in all_csv_rows:\n",
        "    key = (r[\"link\"], r[\"tag\"])\n",
        "    unique[key] = r\n",
        "\n",
        "final_rows = list(unique.values())\n"
      ],
      "metadata": {
        "id": "vKFHcv10gOf1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open(\"tags.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.DictWriter(\n",
        "        f,\n",
        "        fieldnames=[\"link\", \"tag\", \"tag_type\"]\n",
        "    )\n",
        "    writer.writeheader()\n",
        "    writer.writerows(final_rows)\n"
      ],
      "metadata": {
        "id": "pKL2s_REhh8N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_gormsUhkGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}